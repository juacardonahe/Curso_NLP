{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/OI84Q4kgihgB3uOYQc+0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juacardonahe/Curso_NLP/blob/main/2_Mecanismos_Transformers/2.1_Encoder_Decoder/2_1_1_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/juacardonahe/Curso_NLP/refs/heads/main/data/UnFieldB.png\" width=\"40%\">\n",
        "\n",
        "# **Natural Language Procesing (NLP)**\n",
        "### Departamento de Ingeniería Eléctrica, Electrónica y Computación\n",
        "#### Universidad Nacional de Colombia - Sede Manizales\n",
        "\n",
        "#### Created by: Juan José Cardona H.\n",
        "#### Reviewed by: Diego A. Perez"
      ],
      "metadata": {
        "id": "w6UfnTlkRuOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2.1.1 - Seq2Seq Model using Encoder = Decoder**\n",
        "\n",
        "In this notebook, we’ll build a straightforward sequence-to-sequence (Seq2Seq) network with an Encoder–Decoder setup in PyTorch. Seq2Seq models power applications like translating text between languages, condensing articles, and answering questions by reading one sequence (for example, a sentence) and producing another sequence (for example, its translation).\n",
        "\n",
        "We’ll focus on a toy machine‑translation problem: converting German sentences into English. To do this, we’ll use the parallel sentence pairs provided by the Multi30k dataset.\n",
        "\n",
        "**About Multi30k**\n",
        "\n",
        "Multi30k consists of thousands of aligned German–English sentence pairs. Each entry pairs a German sentence with its correct English translation, making it ideal for training translation models.\n",
        "\n",
        "Our workflow will include tokenizing both German and English texts, constructing vocabularies for each language, and training our Seq2Seq model to take German input and generate the corresponding English output."
      ],
      "metadata": {
        "id": "9ExOp9uXRxma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is done in this mini project?\n",
        "\n",
        "1. **Data Preprocessing:**  \n",
        "   We’ll tokenize sentences in German and English and prepare the dataset for training.\n",
        "\n",
        "2. **Model Architecture:**  \n",
        "   - **Encoder:** Reads the source (German) sentence and converts it into a context vector.  \n",
        "   - **Decoder:** Uses the context vector to generate the target (English) sentence.\n",
        "\n",
        "3. **Training:**  \n",
        "   Train the model on the dataset to minimize the loss between the predicted and actual target sentences.\n",
        "\n",
        "4. **Evaluation:**  \n",
        "   We’ll evaluate the model by translating new sentences and computing the BLEU score, which is commonly used to evaluate the quality of machine translations.\n"
      ],
      "metadata": {
        "id": "zYRH2DtnTZ7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Installing libraries**\n",
        "We will use libraries such as torch for deep learning, torchtext to manage datasets, and spacy for tokenizing text."
      ],
      "metadata": {
        "id": "HCGwoSrOTyVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchtext spacy\n",
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "Sf7fpZJbW-lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Import libraries**"
      ],
      "metadata": {
        "id": "wNQMHwqdUSY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import spacy\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.datasets import Multi30k"
      ],
      "metadata": {
        "id": "F3eQeJ5pXL5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Data Pre-Procesing**"
      ],
      "metadata": {
        "id": "p3EMCj79UVae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "def tokenize_de(text):\n",
        " return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
        "def tokenize_en(text):\n",
        " return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "metadata": {
        "id": "AYAXGspWUhKi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Field Definitions**\n",
        "\n",
        "We use `torchtext`’s `Field` to define how the data will be processed. We specify how to tokenize the data and handle the start (`<sos>`) and end (`<eos>`) tokens."
      ],
      "metadata": {
        "id": "angn6Ea7WFFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "wiS99VDWVpPC",
        "outputId": "e74f53bd-7f5c-43e9-cfd0-e1dee86217b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Field' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-622284a78fd0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSRC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTRG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Field' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Loading and Building Vocab**\n",
        "\n",
        "We now load the dataset and build the vocabulary for the source (German) and target (English) languages."
      ],
      "metadata": {
        "id": "F93Hay-IWBN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC, TRG))\n",
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "metadata": {
        "id": "1KHDjUWYVxRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`min_freq=2` ensures that only words that appear at least twice in the training data are included in the vocabulary."
      ],
      "metadata": {
        "id": "JxLdJNCAWNNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Encoder**\n",
        "The Encoder is an RNN that reads a sequence of words (in this case, a German sentence) and encodes it into a context vector."
      ],
      "metadata": {
        "id": "zudt6vutWOJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        " def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        " super().__init__()\n",
        " self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        " self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        " self.dropout = nn.Dropout(dropout)\n",
        "\n",
        " def forward(self, src):\n",
        " # src = [src_len, batch_size]\n",
        " embedded = self.dropout(self.embedding(src)) # [src_len, batch_size, emb_dim]\n",
        " outputs, hidden = self.rnn(embedded)\n",
        " return hidden"
      ],
      "metadata": {
        "id": "JhbzVsIbWXFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. Decoder**\n",
        "The Decoder generates the target sentence (in English) one word at a time, conditioned on the context vector produced by the encoder."
      ],
      "metadata": {
        "id": "KjEjJLipWi9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        " def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        " super().__init__()\n",
        " self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        " self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        " self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        " self.dropout = nn.Dropout(dropout)\n",
        "\n",
        " def forward(self, input, hidden):\n",
        " # input = [batch_size]\n",
        " input = input.unsqueeze(0) # [1, batch_size]\n",
        " embedded = self.dropout(self.embedding(input)) # [1, batch_size, emb_dim]\n",
        " output, hidden = self.rnn(embedded, hidden) # [1, batch_size, hid_dim], [n_layers, batch_size, hid_dim]\n",
        " prediction = self.fc_out(output.squeeze(0)) # [batch_size, output_dim]\n",
        " return prediction, hidden"
      ],
      "metadata": {
        "id": "Jw6QNR0bWnGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Seq2Seq Model**"
      ],
      "metadata": {
        "id": "UsvIGuV2XTMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        " def __init__(self, encoder, decoder, device):\n",
        " super().__init__()\n",
        " self.encoder = encoder\n",
        " self.decoder = decoder\n",
        " self.device = device\n",
        "def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        " trg_len = trg.shape[0]\n",
        " batch_size = trg.shape[1]\n",
        " trg_vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        " outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        " hidden = self.encoder(src)\n",
        "\n",
        " input = trg[0, :]\n",
        " for t in range(1, trg_len):\n",
        " output, hidden = self.decoder(input, hidden)\n",
        " outputs[t] = output\n",
        " top1 = output.argmax(1)\n",
        " input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
        "\n",
        " return outputs"
      ],
      "metadata": {
        "id": "aFp7wvjvXWBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6. Training the model**\n",
        "We define the training loop, where we feed in the German sentence, run it through the Seq2Seq model, and compute the loss using Cross Entropy."
      ],
      "metadata": {
        "id": "JDVnub6hXY3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        " model.train()\n",
        " epoch_loss = 0\n",
        "\n",
        " for i, batch in enumerate(iterator):\n",
        " src = batch.src\n",
        " trg = batch.trg\n",
        "\n",
        " optimizer.zero_grad()\n",
        " output = model(src, trg)\n",
        "\n",
        " output_dim = output.shape[-1]\n",
        " output = output[1:].view(-1, output_dim)\n",
        " trg = trg[1:].view(-1)\n",
        "\n",
        " loss = criterion(output, trg)\n",
        " loss.backward()\n",
        " torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        " optimizer.step()\n",
        " epoch_loss += loss.item()\n",
        "\n",
        " return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "Ueh3Q2gfXchB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**7. Evaluate the model**\n",
        "Evaluation works similarly to training, but we disable backpropagation since we’re only interested in the model’s performance."
      ],
      "metadata": {
        "id": "WkyTws6HXhjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        " model.eval()\n",
        " epoch_loss = 0\n",
        "\n",
        " with torch.no_grad():\n",
        " for i, batch in enumerate(iterator):\n",
        " src = batch.src\n",
        " trg = batch.trg\n",
        " output = model(src, trg, 0)\n",
        "\n",
        " output_dim = output.shape[-1]\n",
        " output = output[1:].view(-1, output_dim)\n",
        " trg = trg[1:].view(-1)\n",
        "loss = criterion(output, trg)\n",
        " epoch_loss += loss.item()\n",
        "\n",
        " return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "YSfvV7v7XmHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**8. Initialize the model**\n",
        "Now, we initialize the model, optimizer, and loss function, and specify hyperparameters."
      ],
      "metadata": {
        "id": "h4PXtZzNXyre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "0E0f-xddX4PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**9. Training loop**\n",
        "We train the model for a set number of epochs.\n"
      ],
      "metadata": {
        "id": "R1C_4COJX6dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        " train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        " valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        " print(f'Epoch: {epoch+1}')\n",
        " print(f'Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "id": "YVKbwRJ4YAi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**10. BLEU Score**\n",
        "Finally, we can test our model by translating new sentences and evaluating the BLEU score."
      ],
      "metadata": {
        "id": "LGX6qPhIYGMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        " model.eval()\n",
        " tokens = [token.text.lower() for token in spacy_de(sentence)]\n",
        " tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        " src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        " src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        " with torch.no_grad():\n",
        " hidden = model.encoder(src_tensor)\n",
        "\n",
        " trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        " for i in range(max_len):\n",
        " trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        " with torch.no_grad():\n",
        " output, hidden = model.decoder(trg_tensor, hidden)\n",
        " pred_token = output.argmax(1).item()\n",
        " trg_indexes.append(pred_token)\n",
        " if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        " break\n",
        " trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        " return trg_tokens[1:]"
      ],
      "metadata": {
        "id": "n30y5YIPYJFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function translates a sentence from German to English using the trained Seq2Seq model."
      ],
      "metadata": {
        "id": "2k-ADvtFYPtW"
      }
    }
  ]
}